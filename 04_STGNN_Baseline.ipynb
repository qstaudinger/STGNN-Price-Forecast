{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HINWEIS: Hier arbeite ich aktuell noch aktiv dran (siehe PDF, S. 15). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/qusta100/STGNN\n"
     ]
    }
   ],
   "source": [
    "# Standard libs\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from __future__ import annotations\n",
    "\n",
    "# Utils\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Data & Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix\n",
    "from sklearn.neighbors import BallTree, NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TQDM\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "# Confirm the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\n",
    "    \"/gpfs/scratch/qusta100/STGNN/Data/Temp/final.csv\",\n",
    "    dtype={9: str}\n",
    ")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_uuid</th>\n",
       "      <th>diesel</th>\n",
       "      <th>e5</th>\n",
       "      <th>e10</th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>street</th>\n",
       "      <th>house_number</th>\n",
       "      <th>...</th>\n",
       "      <th>openingtimes_json</th>\n",
       "      <th>day</th>\n",
       "      <th>in_thuringia</th>\n",
       "      <th>in_region</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>is_open</th>\n",
       "      <th>weekday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>time</th>\n",
       "      <th>Brent_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-01 00:00:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-01 00:15:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:15</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-01 00:30:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01 00:45:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:45</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01 01:00:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>01:00</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                          station_uuid  diesel     e5  \\\n",
       "0  2025-04-01 00:00:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "1  2025-04-01 00:15:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "2  2025-04-01 00:30:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "3  2025-04-01 00:45:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "4  2025-04-01 01:00:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "\n",
       "     e10                                  uuid               name  \\\n",
       "0  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "1  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "2  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "3  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "4  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "\n",
       "                    brand            street house_number  ...  \\\n",
       "0  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...   \n",
       "1  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...   \n",
       "2  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...   \n",
       "3  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...   \n",
       "4  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...   \n",
       "\n",
       "   openingtimes_json         day  in_thuringia  in_region  \\\n",
       "0                 {}  2025-04-30         False          1   \n",
       "1                 {}  2025-04-30         False          1   \n",
       "2                 {}  2025-04-30         False          1   \n",
       "3                 {}  2025-04-30         False          1   \n",
       "4                 {}  2025-04-30         False          1   \n",
       "\n",
       "             last_seen is_open  weekday  holiday   time Brent_Price  \n",
       "0  2025-04-30 21:45:00    True  Tuesday        0  00:00   74.959999  \n",
       "1  2025-04-30 21:45:00    True  Tuesday        0  00:15   74.959999  \n",
       "2  2025-04-30 21:45:00    True  Tuesday        0  00:30   74.959999  \n",
       "3  2025-04-30 21:45:00    True  Tuesday        0  00:45   74.959999  \n",
       "4  2025-04-30 21:45:00    True  Tuesday        0  01:00   74.959999  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for one specific day\n",
    "# Because of limited computational resources, I restrict the dataset to a single day, which gives me 96 observations.\n",
    "df = df[df['date'].str.startswith(\"2025-04-01\")]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. STGNN Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# a) Parameters\n",
    "# =============================\n",
    "\n",
    "STATION_COL = \"station_uuid\"\n",
    "LAT_COL = \"latitude\"\n",
    "LON_COL = \"longitude\"\n",
    "TARGET_COL = \"e5\"\n",
    "TIME_COL = \"date\"\n",
    "\n",
    "RADIUS_KM = 10.0\n",
    "\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "SEED = 42\n",
    "\n",
    "WINDOW_SIZE = 16\n",
    "HORIZON_STEPS = 4\n",
    "\n",
    "\n",
    "# =============================\n",
    "# b) Helper functions\n",
    "# =============================\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def km_to_radians(km: float) -> float:\n",
    "    earth_radius_km = 6371.0088\n",
    "    return km / earth_radius_km\n",
    "\n",
    "\n",
    "def build_radius_graph(lat_lon_deg: np.ndarray, radius_km: float) -> np.ndarray:\n",
    "    lat_lon_rad = np.radians(lat_lon_deg)\n",
    "    tree = BallTree(lat_lon_rad, metric=\"haversine\")\n",
    "    rad = km_to_radians(radius_km)\n",
    "\n",
    "    ind = tree.query_radius(lat_lon_rad, r=rad, return_distance=False)\n",
    "\n",
    "    src, dst = [], []\n",
    "    for i, neigh in enumerate(ind):\n",
    "        for j in neigh:\n",
    "            if i == j:\n",
    "                continue\n",
    "            src.append(j)\n",
    "            dst.append(i)\n",
    "    edge_index = np.vstack([np.array(src), np.array(dst)])\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "# =============================\n",
    "# c) Window-based ST data (multi-step)\n",
    "# =============================\n",
    "\n",
    "@dataclass\n",
    "class STWindowDataMulti:\n",
    "    x: torch.Tensor             # [T, N, F] full time series\n",
    "    y: torch.Tensor             # [T, N, H] H horizons for each t\n",
    "    edge_index: torch.Tensor\n",
    "    train_end_idx: np.ndarray   # time indices where windows end (train)\n",
    "    val_end_idx: np.ndarray     # time indices (validation)\n",
    "    test_end_idx: np.ndarray    # time indices (test)\n",
    "    valid_nodes: np.ndarray     # node indices (e.g. Thüringen)\n",
    "    times: np.ndarray           # sorted timestamps\n",
    "    meta: pd.DataFrame          # station metadata (uuid, lat, lon, node_id)\n",
    "\n",
    "\n",
    "def make_window_data_multi_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    window_size: int = WINDOW_SIZE,\n",
    "    horizon_steps: int = HORIZON_STEPS\n",
    ") -> STWindowDataMulti:\n",
    "\n",
    "    needed = [STATION_COL, LAT_COL, LON_COL, TARGET_COL, TIME_COL, \"in_thuringia\"]\n",
    "    assert all(c in df.columns for c in needed), f\"Missing columns: {set(needed) - set(df.columns)}\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Stations + node ids\n",
    "    stations = df[[STATION_COL, LAT_COL, LON_COL]].drop_duplicates().reset_index(drop=True)\n",
    "    stations[\"node_id\"] = np.arange(len(stations))\n",
    "    station2id = stations.set_index(STATION_COL)[\"node_id\"].to_dict()\n",
    "\n",
    "    # Time axis\n",
    "    times = np.sort(df[TIME_COL].unique())\n",
    "    time2id = {t: i for i, t in enumerate(times)}\n",
    "\n",
    "    N = len(stations)\n",
    "    T = len(times)\n",
    "    F = 1    # only price used as feature\n",
    "    H = horizon_steps\n",
    "\n",
    "    # Spatial graph\n",
    "    lat_lon = stations[[LAT_COL, LON_COL]].to_numpy(dtype=float)\n",
    "    edge_index_np = build_radius_graph(lat_lon, RADIUS_KM)\n",
    "    edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "\n",
    "    # Tensors\n",
    "    x = torch.zeros((T, N, F), dtype=torch.float32)\n",
    "    y = torch.full((T, N, H), float(\"nan\"), dtype=torch.float32)\n",
    "\n",
    "    # Aggregate per (station, time) and drop NaN prices\n",
    "    df_idx = (\n",
    "        df[[STATION_COL, TIME_COL, TARGET_COL]]\n",
    "        .dropna(subset=[TARGET_COL])\n",
    "        .groupby([STATION_COL, TIME_COL], as_index=False)\n",
    "        .mean()\n",
    "        .sort_values(TIME_COL)\n",
    "    )\n",
    "\n",
    "    df_idx[\"node_id\"] = df_idx[STATION_COL].map(station2id)\n",
    "    df_idx[\"time_id\"] = df_idx[TIME_COL].map(time2id)\n",
    "\n",
    "    # x[t] = price at time t\n",
    "    for _, row in df_idx.iterrows():\n",
    "        t = int(row[\"time_id\"])\n",
    "        n = int(row[\"node_id\"])\n",
    "        v = float(row[TARGET_COL])\n",
    "        x[t, n, 0] = v\n",
    "\n",
    "    # y[t, :, h] = price at t + h + 1\n",
    "    for station, g in df_idx.groupby(STATION_COL):\n",
    "        g = g.sort_values(\"time_id\")\n",
    "        node_id = int(g[\"node_id\"].iloc[0])\n",
    "        t_ids = g[\"time_id\"].to_numpy()\n",
    "        vals  = g[TARGET_COL].to_numpy()\n",
    "\n",
    "        L = len(t_ids)\n",
    "        for idx in range(L):\n",
    "            t = int(t_ids[idx])\n",
    "            if idx + H >= L:\n",
    "                break\n",
    "            for h in range(H):\n",
    "                y[t, node_id, h] = float(vals[idx + h + 1])\n",
    "\n",
    "    # Time indices where full horizon is available\n",
    "    effective_T = T - H\n",
    "    if effective_T < window_size:\n",
    "        raise ValueError(f\"Too few timesteps ({effective_T}) for window size {window_size} and horizon {H}.\")\n",
    "\n",
    "    # Time-based split over base indices 0..effective_T-1\n",
    "    time_indices = np.arange(effective_T)\n",
    "    num_total = len(time_indices)\n",
    "    num_train = int((1.0 - VAL_SPLIT - TEST_SPLIT) * num_total)\n",
    "    num_val   = int(VAL_SPLIT * num_total)\n",
    "    num_test  = num_total - num_train - num_val\n",
    "\n",
    "    train_t = time_indices[:num_train]\n",
    "    val_t   = time_indices[num_train:num_train + num_val]\n",
    "    test_t  = time_indices[num_train + num_val:]\n",
    "\n",
    "    # Window end indices must satisfy t >= window_size - 1\n",
    "    min_end = window_size - 1\n",
    "    train_end_idx = train_t[train_t >= min_end]\n",
    "    val_end_idx   = val_t[val_t >= min_end]\n",
    "    test_end_idx  = test_t[test_t >= min_end]\n",
    "\n",
    "    # Thüringen mask for nodes\n",
    "    th_mask = (\n",
    "        df[[STATION_COL, \"in_thuringia\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(STATION_COL)[\"in_thuringia\"]\n",
    "    )\n",
    "    stations = stations.join(th_mask, on=STATION_COL)\n",
    "    valid_nodes = stations.index[stations[\"in_thuringia\"] == 1].to_numpy()\n",
    "\n",
    "    if valid_nodes.size == 0:\n",
    "        raise ValueError(\"No nodes with in_thuringia == 1 found.\")\n",
    "\n",
    "    meta = stations[[STATION_COL, LAT_COL, LON_COL, \"node_id\"]].copy()\n",
    "\n",
    "    return STWindowDataMulti(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        edge_index=edge_index,\n",
    "        train_end_idx=train_end_idx,\n",
    "        val_end_idx=val_end_idx,\n",
    "        test_end_idx=test_end_idx,\n",
    "        valid_nodes=valid_nodes,\n",
    "        times=times,\n",
    "        meta=meta\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================\n",
    "# d) STGNN with windowing (multi-step output)\n",
    "# =============================\n",
    "\n",
    "class STGNNWindowMultiRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes: int, embed_dim: int, hidden_dim: int, horizon_steps: int, in_dim: int = 1):\n",
    "        super().__init__()\n",
    "        self.horizon_steps = horizon_steps\n",
    "        self.emb = nn.Embedding(num_nodes, embed_dim)\n",
    "        self.proj = nn.Linear(in_dim + embed_dim, hidden_dim)\n",
    "        self.conv = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=False)\n",
    "        self.head = nn.Linear(hidden_dim, horizon_steps)\n",
    "\n",
    "    def forward(self, x_window: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        W, N, F = x_window.shape\n",
    "        node_emb = self.emb.weight\n",
    "\n",
    "        gnn_out_per_t = []\n",
    "\n",
    "        for t in range(W):\n",
    "            xt = x_window[t]\n",
    "            h = torch.cat([xt, node_emb], dim=1)\n",
    "            h = self.proj(h)\n",
    "            h = self.act(h)\n",
    "            h = self.conv(h, edge_index)\n",
    "            h = self.act(h)\n",
    "            gnn_out_per_t.append(h)\n",
    "\n",
    "        gnn_seq = torch.stack(gnn_out_per_t, dim=0)\n",
    "\n",
    "        gru_out, h_n = self.gru(gnn_seq)\n",
    "        last_hidden = h_n[-1]\n",
    "\n",
    "        out = self.head(last_hidden)\n",
    "        return out\n",
    "\n",
    "\n",
    "# =============================\n",
    "# e) Training and evaluation (multi-step)\n",
    "# =============================\n",
    "\n",
    "@dataclass\n",
    "class STTrainConfig:\n",
    "    lr: float = LR\n",
    "    weight_decay: float = WEIGHT_DECAY\n",
    "    epochs: int = EPOCHS\n",
    "    patience: int = PATIENCE\n",
    "    window_size: int = WINDOW_SIZE\n",
    "    horizon_steps: int = HORIZON_STEPS\n",
    "\n",
    "\n",
    "def _compute_window_metrics_multi(\n",
    "    model: nn.Module,\n",
    "    data: STWindowDataMulti,\n",
    "    end_indices: np.ndarray,\n",
    "    device: torch.device,\n",
    "    loss_nodes: torch.Tensor,\n",
    ") -> dict:\n",
    "\n",
    "    x_full = data.x.to(device)\n",
    "    y_full = data.y.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    W = WINDOW_SIZE\n",
    "    H = y_full.shape[-1]\n",
    "\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for end_t in end_indices:\n",
    "            start_t = end_t - W + 1\n",
    "            x_win = x_full[start_t:end_t+1]\n",
    "            y_target = y_full[end_t]\n",
    "\n",
    "            pred = model(x_win, edge_index)\n",
    "\n",
    "            y_nodes = y_target[loss_nodes]\n",
    "            p_nodes = pred[loss_nodes]\n",
    "\n",
    "            mask = torch.isfinite(y_nodes)\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            preds_all.append(p_nodes[mask].cpu().numpy())\n",
    "            trues_all.append(y_nodes[mask].cpu().numpy())\n",
    "\n",
    "    if len(preds_all) == 0:\n",
    "        return {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\")}\n",
    "\n",
    "    preds_concat = np.concatenate(preds_all)\n",
    "    trues_concat = np.concatenate(trues_all)\n",
    "\n",
    "    mae = np.mean(np.abs(preds_concat - trues_concat))\n",
    "    mse = np.mean((preds_concat - trues_concat) ** 2)\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    "\n",
    "\n",
    "def train_stgnn_window_multi(data: STWindowDataMulti, cfg: STTrainConfig) -> dict:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_full = data.x.to(device)\n",
    "    y_full = data.y.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    W = cfg.window_size\n",
    "    H = cfg.horizon_steps\n",
    "\n",
    "    model = STGNNWindowMultiRegressor(\n",
    "        num_nodes=x_full.shape[1],\n",
    "        embed_dim=EMBED_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        horizon_steps=H,\n",
    "        in_dim=x_full.shape[2]\n",
    "    ).to(device)\n",
    "\n",
    "    opt = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    loss_nodes = torch.tensor(data.valid_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float(\"inf\")\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for end_t in data.train_end_idx:\n",
    "            start_t = end_t - W + 1\n",
    "\n",
    "            x_win = x_full[start_t:end_t+1]\n",
    "            y_target = y_full[end_t]\n",
    "\n",
    "            pred = model(x_win, edge_index)\n",
    "\n",
    "            y_nodes = y_target[loss_nodes]\n",
    "            p_nodes = pred[loss_nodes]\n",
    "\n",
    "            mask = torch.isfinite(y_nodes)\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            loss = loss_fn(p_nodes[mask], y_nodes[mask])\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        avg_train_loss = epoch_loss / max(count, 1)\n",
    "\n",
    "        val_metrics = _compute_window_metrics_multi(model, data, data.val_end_idx, device, loss_nodes)\n",
    "        val_mae = val_metrics[\"MAE\"]\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_MAE={val_mae:.4f}\")\n",
    "\n",
    "        if val_mae < best_val:\n",
    "            best_val = val_mae\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= cfg.patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    test_metrics = _compute_window_metrics_multi(model, data, data.test_end_idx, device, loss_nodes)\n",
    "    val_metrics = _compute_window_metrics_multi(model, data, data.val_end_idx, device, loss_nodes)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"metrics\": {\n",
    "            \"val\": val_metrics,\n",
    "            \"test\": test_metrics,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================\n",
    "# f) High-level API\n",
    "# =============================\n",
    "\n",
    "def train_stgnn_window_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    seed: int = SEED,\n",
    "    window_size: int = WINDOW_SIZE,\n",
    "    horizon_steps: int = HORIZON_STEPS\n",
    ") -> dict:\n",
    "\n",
    "    set_seed(seed)\n",
    "    data = make_window_data_multi_from_df(df, window_size=window_size, horizon_steps=horizon_steps)\n",
    "    cfg = STTrainConfig(window_size=window_size, horizon_steps=horizon_steps)\n",
    "    result = train_stgnn_window_multi(data, cfg)\n",
    "\n",
    "    return {\n",
    "        \"model\": result[\"model\"],\n",
    "        \"metrics\": result[\"metrics\"],\n",
    "        \"data\": data,\n",
    "        \"window_size\": window_size,\n",
    "        \"horizon_steps\": horizon_steps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.2343, val_MAE=0.0663\n",
      "Epoch 2: train_loss=0.0034, val_MAE=0.0422\n",
      "Epoch 3: train_loss=0.0027, val_MAE=0.0375\n",
      "Epoch 4: train_loss=0.0026, val_MAE=0.0347\n",
      "Epoch 5: train_loss=0.0025, val_MAE=0.0340\n",
      "Epoch 6: train_loss=0.0024, val_MAE=0.0337\n",
      "Epoch 7: train_loss=0.0023, val_MAE=0.0328\n",
      "Epoch 8: train_loss=0.0022, val_MAE=0.0314\n",
      "Epoch 9: train_loss=0.0021, val_MAE=0.0299\n",
      "Epoch 10: train_loss=0.0020, val_MAE=0.0286\n",
      "Epoch 11: train_loss=0.0019, val_MAE=0.0275\n",
      "Epoch 12: train_loss=0.0018, val_MAE=0.0266\n",
      "Epoch 13: train_loss=0.0017, val_MAE=0.0258\n",
      "Epoch 14: train_loss=0.0016, val_MAE=0.0251\n",
      "Epoch 15: train_loss=0.0015, val_MAE=0.0243\n",
      "Epoch 16: train_loss=0.0014, val_MAE=0.0235\n",
      "Epoch 17: train_loss=0.0013, val_MAE=0.0226\n",
      "Epoch 18: train_loss=0.0013, val_MAE=0.0217\n",
      "Epoch 19: train_loss=0.0012, val_MAE=0.0208\n",
      "Epoch 20: train_loss=0.0011, val_MAE=0.0200\n",
      "Epoch 21: train_loss=0.0011, val_MAE=0.0192\n",
      "Epoch 22: train_loss=0.0010, val_MAE=0.0186\n",
      "Epoch 23: train_loss=0.0010, val_MAE=0.0179\n",
      "Epoch 24: train_loss=0.0010, val_MAE=0.0174\n",
      "Epoch 25: train_loss=0.0010, val_MAE=0.0169\n",
      "Epoch 26: train_loss=0.0009, val_MAE=0.0166\n",
      "Epoch 27: train_loss=0.0009, val_MAE=0.0164\n",
      "Epoch 28: train_loss=0.0009, val_MAE=0.0162\n",
      "Epoch 29: train_loss=0.0009, val_MAE=0.0160\n",
      "Epoch 30: train_loss=0.0009, val_MAE=0.0159\n",
      "Epoch 31: train_loss=0.0009, val_MAE=0.0158\n",
      "Epoch 32: train_loss=0.0009, val_MAE=0.0157\n",
      "Epoch 33: train_loss=0.0009, val_MAE=0.0156\n",
      "Epoch 34: train_loss=0.0009, val_MAE=0.0155\n",
      "Epoch 35: train_loss=0.0009, val_MAE=0.0155\n",
      "Epoch 36: train_loss=0.0009, val_MAE=0.0154\n",
      "Epoch 37: train_loss=0.0009, val_MAE=0.0153\n",
      "Epoch 38: train_loss=0.0009, val_MAE=0.0153\n",
      "Epoch 39: train_loss=0.0008, val_MAE=0.0152\n",
      "Epoch 40: train_loss=0.0008, val_MAE=0.0152\n",
      "Epoch 41: train_loss=0.0008, val_MAE=0.0152\n",
      "Epoch 42: train_loss=0.0008, val_MAE=0.0151\n",
      "Epoch 43: train_loss=0.0008, val_MAE=0.0151\n",
      "Epoch 44: train_loss=0.0008, val_MAE=0.0151\n",
      "Epoch 45: train_loss=0.0008, val_MAE=0.0150\n",
      "Epoch 46: train_loss=0.0008, val_MAE=0.0150\n",
      "Epoch 47: train_loss=0.0008, val_MAE=0.0149\n",
      "Epoch 48: train_loss=0.0008, val_MAE=0.0149\n",
      "Epoch 49: train_loss=0.0008, val_MAE=0.0149\n",
      "Epoch 50: train_loss=0.0008, val_MAE=0.0148\n",
      "Val: {'MAE': 0.014842815697193146, 'RMSE': 0.0188124579399651}\n",
      "Test: {'MAE': 0.02395385317504406, 'RMSE': 0.032192786897090174}\n"
     ]
    }
   ],
   "source": [
    "# Example with a window size of 16 and 4 horizon steps\n",
    "res = train_stgnn_window_from_df(df, window_size=16, horizon_steps=4)\n",
    "\n",
    "print(\"Val:\", res[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", res[\"metrics\"][\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
