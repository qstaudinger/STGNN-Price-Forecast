{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/qusta100/STGNN\n"
     ]
    }
   ],
   "source": [
    "# Standard libs\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Utils\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Data & Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix\n",
    "from sklearn.neighbors import BallTree, NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TQDM\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GatedGraphConv, GATConv\n",
    "\n",
    "\n",
    "# Confirm the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\n",
    "    \"/gpfs/scratch/qusta100/STGNN/Data/Temp/final.csv\",\n",
    "    dtype={9: str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_uuid</th>\n",
       "      <th>diesel</th>\n",
       "      <th>e5</th>\n",
       "      <th>e10</th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>street</th>\n",
       "      <th>house_number</th>\n",
       "      <th>...</th>\n",
       "      <th>in_thuringia</th>\n",
       "      <th>in_region</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>is_open</th>\n",
       "      <th>weekday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>brand_cat</th>\n",
       "      <th>Brent_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-01 00:00:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-01 00:15:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065403</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-01 00:30:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01 00:45:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01 01:00:00</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.709</td>\n",
       "      <td>1.649</td>\n",
       "      <td>00060065-7890-4444-8888-acdc00000004</td>\n",
       "      <td>Georg Ultsch GmbH</td>\n",
       "      <td>Tankstelle Lichtenfels</td>\n",
       "      <td>Robert-Koch-Str.</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 21:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.959999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                          station_uuid  diesel     e5  \\\n",
       "0 2025-04-01 00:00:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "1 2025-04-01 00:15:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "2 2025-04-01 00:30:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "3 2025-04-01 00:45:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "4 2025-04-01 01:00:00  00060065-7890-4444-8888-acdc00000004   1.559  1.709   \n",
       "\n",
       "     e10                                  uuid               name  \\\n",
       "0  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "1  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "2  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "3  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "4  1.649  00060065-7890-4444-8888-acdc00000004  Georg Ultsch GmbH   \n",
       "\n",
       "                    brand            street house_number  ...  in_thuringia  \\\n",
       "0  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...         False   \n",
       "1  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...         False   \n",
       "2  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...         False   \n",
       "3  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...         False   \n",
       "4  Tankstelle Lichtenfels  Robert-Koch-Str.           18  ...         False   \n",
       "\n",
       "  in_region            last_seen  is_open weekday holiday  time_sin  time_cos  \\\n",
       "0         1  2025-04-30 21:45:00     True       1       0  0.000000  1.000000   \n",
       "1         1  2025-04-30 21:45:00     True       1       0  0.065403  0.997859   \n",
       "2         1  2025-04-30 21:45:00     True       1       0  0.130526  0.991445   \n",
       "3         1  2025-04-30 21:45:00     True       1       0  0.195090  0.980785   \n",
       "4         1  2025-04-30 21:45:00     True       1       0  0.258819  0.965926   \n",
       "\n",
       "  brand_cat  Brent_Price  \n",
       "0      74.0    74.959999  \n",
       "1      74.0    74.959999  \n",
       "2      74.0    74.959999  \n",
       "3      74.0    74.959999  \n",
       "4      74.0    74.959999  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for one specific day\n",
    "# Because of limited computational resources, I restrict the dataset to a single day, which gives me 96 observations.\n",
    "#df = df[df['date'].str.startswith(\"2025-04-01\")]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. STGNN Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# a) Parameters\n",
    "# =============================\n",
    "\n",
    "STATION_COL = \"station_uuid\"\n",
    "LAT_COL = \"latitude\"\n",
    "LON_COL = \"longitude\"\n",
    "TIME_COL = \"date\"\n",
    "\n",
    "# Default-Targets\n",
    "TARGET_COLS_DEFAULT = [\"e5\", \"e10\"]\n",
    "FEATURE_COLS_DEFAULT = [\"e5\", \"e10\"]  # standard: Targets = Features\n",
    "\n",
    "RADIUS_KM = 10\n",
    "NEIGHBOUR = 5\n",
    "\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "SEED = 42\n",
    "\n",
    "WINDOW_SIZE = 16\n",
    "HORIZON_STEPS = 4  # Horizont per Target\n",
    "\n",
    "\n",
    "# =============================\n",
    "# b) Helper functions\n",
    "# =============================\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def km_to_radians(km: float) -> float:\n",
    "    earth_radius_km = 6371.0088\n",
    "    return km / earth_radius_km\n",
    "\n",
    "\n",
    "def build_knn_graph(\n",
    "    lat_lon_deg: np.ndarray,\n",
    "    k: int = 5,\n",
    "    return_dists: bool = False,\n",
    "    RADIUS_KM: Optional[float] = None\n",
    ") -> np.ndarray | Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    lat_lon_rad = np.radians(lat_lon_deg)\n",
    "    tree = BallTree(lat_lon_rad, metric=\"haversine\")\n",
    "\n",
    "    dist_rad, ind = tree.query(lat_lon_rad, k=k + 1)\n",
    "\n",
    "    src, dst, dists_km = [], [], []\n",
    "    radius_rad = km_to_radians(RADIUS_KM) if RADIUS_KM is not None else None\n",
    "\n",
    "    for i, (neigh_idx, neigh_dist_rad) in enumerate(zip(ind, dist_rad)):\n",
    "        for j, dij_rad in zip(neigh_idx[1:], neigh_dist_rad[1:]):\n",
    "            if radius_rad is not None and dij_rad > radius_rad:\n",
    "                continue\n",
    "\n",
    "            dij_km = dij_rad * 6371.0088  # Conversion for output\n",
    "            src.append(j)\n",
    "            dst.append(i)\n",
    "            dists_km.append(dij_km)\n",
    "\n",
    "    edge_index = np.vstack([np.array(src, dtype=int), np.array(dst, dtype=int)])\n",
    "\n",
    "    if return_dists:\n",
    "        return edge_index, np.asarray(dists_km, dtype=float)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "# =============================\n",
    "# c) Window-based ST data (multi-step, multi-target)\n",
    "# =============================\n",
    "\n",
    "@dataclass\n",
    "class STWindowDataMulti:\n",
    "    x: torch.Tensor             # [T, N, F] full time series, F = num_features\n",
    "    y: torch.Tensor             # [T, N, H * num_targets] H Horizonte für alle Targets\n",
    "    edge_index: torch.Tensor\n",
    "    train_end_idx: np.ndarray   # time indices where windows end (train)\n",
    "    val_end_idx: np.ndarray     # time indices (validation)\n",
    "    test_end_idx: np.ndarray    # time indices (test)\n",
    "    valid_nodes: np.ndarray     # node indices (z.B. Thüringen)\n",
    "    times: np.ndarray           # sorted timestamps\n",
    "    meta: pd.DataFrame          # station metadata (uuid, lat, lon, node_id)\n",
    "    feature_cols: List[str]     # relevant Feature-Spalten\n",
    "    target_cols: List[str]      # relevant Target-Spalten\n",
    "\n",
    "\n",
    "def make_window_data_multi_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    window_size: int = WINDOW_SIZE,\n",
    "    horizon_steps: int = HORIZON_STEPS,\n",
    "    feature_cols: Optional[List[str]] = None,\n",
    "    target_cols: Optional[List[str]] = None,\n",
    "    stride: int = 1, \n",
    "    WINDOW_SIZE: int = 16,\n",
    "    HORIZON_STEPS: int = 4,\n",
    ") -> STWindowDataMulti:\n",
    "\n",
    "    if target_cols is None:\n",
    "        target_cols = TARGET_COLS_DEFAULT\n",
    "    if feature_cols is None:\n",
    "        feature_cols = FEATURE_COLS_DEFAULT\n",
    "\n",
    "    # Necessary Columns\n",
    "    base_cols = [STATION_COL, LAT_COL, LON_COL, TIME_COL, \"in_thuringia\"]\n",
    "    all_val_cols = sorted(set(feature_cols) | set(target_cols))\n",
    "    needed = base_cols + all_val_cols\n",
    "    assert all(c in df.columns for c in needed), f\"Missing columns: {set(needed) - set(df.columns)}\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Stations + node ids\n",
    "    stations = df[[STATION_COL, LAT_COL, LON_COL]].drop_duplicates().reset_index(drop=True)\n",
    "    stations[\"node_id\"] = np.arange(len(stations))\n",
    "    station2id = stations.set_index(STATION_COL)[\"node_id\"].to_dict()\n",
    "\n",
    "    # Time axis\n",
    "    times = np.sort(df[TIME_COL].unique())\n",
    "    time2id = {t: i for i, t in enumerate(times)}\n",
    "\n",
    "    N = len(stations)\n",
    "    T = len(times)\n",
    "    M = len(target_cols)             # Number Targets\n",
    "    F = len(feature_cols)           # Number Features\n",
    "    H = horizon_steps\n",
    "\n",
    "    # Spatial graph\n",
    "    lat_lon = stations[[LAT_COL, LON_COL]].to_numpy(dtype=float)\n",
    "    edge_index_np = build_knn_graph(\n",
    "        lat_lon_deg=lat_lon,\n",
    "        k=NEIGHBOUR,\n",
    "        RADIUS_KM=RADIUS_KM\n",
    "    )\n",
    "    edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "\n",
    "    # Tensors\n",
    "    x = torch.zeros((T, N, F), dtype=torch.float32)              # [T, N, F]\n",
    "    y = torch.full((T, N, H * M), float(\"nan\"), dtype=torch.float32)  # [T, N, H*M]\n",
    "\n",
    "    # Aggregation per (station, time) across all relevant columns\n",
    "    df_idx = (\n",
    "        df[[STATION_COL, TIME_COL] + all_val_cols]\n",
    "        .groupby([STATION_COL, TIME_COL], as_index=False)\n",
    "        .mean()\n",
    "        .sort_values(TIME_COL)\n",
    "    )\n",
    "\n",
    "    df_idx[\"node_id\"] = df_idx[STATION_COL].map(station2id)\n",
    "    df_idx[\"time_id\"] = df_idx[TIME_COL].map(time2id)\n",
    "\n",
    "    # x[t, n, f] = Features at time t\n",
    "    for _, row in df_idx.iterrows():\n",
    "        t = int(row[\"time_id\"])\n",
    "        n = int(row[\"node_id\"])\n",
    "        for f_idx, col in enumerate(feature_cols):\n",
    "            v = row[col]\n",
    "            if pd.notna(v):\n",
    "                x[t, n, f_idx] = float(v)\n",
    "\n",
    "    # y[t, n, m*H + h] = Target m at time t+h+1\n",
    "    for station, g in df_idx.groupby(STATION_COL):\n",
    "        g = g.sort_values(\"time_id\")\n",
    "        node_id = int(g[\"node_id\"].iloc[0])\n",
    "        t_ids = g[\"time_id\"].to_numpy()\n",
    "\n",
    "        L = len(t_ids)\n",
    "        for m, col in enumerate(target_cols):\n",
    "            vals = g[col].to_numpy()\n",
    "\n",
    "            for idx in range(L):\n",
    "                t = int(t_ids[idx])\n",
    "                if idx + H >= L:\n",
    "                    break\n",
    "\n",
    "                future_vals = vals[idx + 1: idx + 1 + H]\n",
    "\n",
    "                # If there are NaNs in the horizon for this target, skip this start time\n",
    "                if np.any(np.isnan(future_vals)):\n",
    "                    continue\n",
    "\n",
    "                for h in range(H):\n",
    "                    y[t, node_id, m * H + h] = float(future_vals[h])\n",
    "\n",
    "    # Time indices where full horizon is available\n",
    "    effective_T = T - H\n",
    "    if effective_T < window_size:\n",
    "        raise ValueError(f\"Too few timesteps ({effective_T}) for window size {window_size} and horizon {H}.\")\n",
    "\n",
    "    # Time-based split over 0..effective_T-1\n",
    "    time_indices = np.arange(effective_T)\n",
    "    num_total = len(time_indices)\n",
    "    num_train = int((1.0 - VAL_SPLIT - TEST_SPLIT) * num_total)\n",
    "    num_val   = int(VAL_SPLIT * num_total)\n",
    "    num_test  = num_total - num_train - num_val\n",
    "\n",
    "    train_t = time_indices[:num_train]\n",
    "    val_t   = time_indices[num_train:num_train + num_val]\n",
    "    test_t  = time_indices[num_train + num_val:]\n",
    "\n",
    "    # Window end indices\n",
    "    min_end = window_size - 1\n",
    "    train_end_idx = train_t[train_t >= min_end]\n",
    "    val_end_idx   = val_t[val_t >= min_end]\n",
    "    test_end_idx  = test_t[test_t >= min_end]\n",
    "    \n",
    "    #30min\n",
    "    train_end_idx = train_end_idx[::stride]\n",
    "    val_end_idx   = val_end_idx[::stride]\n",
    "    test_end_idx  = test_end_idx[::stride]\n",
    "\n",
    "\n",
    "    # Thuringia mask\n",
    "    th_mask = (\n",
    "        df[[STATION_COL, \"in_thuringia\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(STATION_COL)[\"in_thuringia\"]\n",
    "    )\n",
    "    stations = stations.join(th_mask, on=STATION_COL)\n",
    "    valid_nodes = stations.index[stations[\"in_thuringia\"] == 1].to_numpy()\n",
    "\n",
    "    if valid_nodes.size == 0:\n",
    "        raise ValueError(\"No nodes with in_thuringia == 1 found.\")\n",
    "\n",
    "    meta = stations[[STATION_COL, LAT_COL, LON_COL, \"node_id\"]].copy()\n",
    "\n",
    "    return STWindowDataMulti(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        edge_index=edge_index,\n",
    "        train_end_idx=train_end_idx,\n",
    "        val_end_idx=val_end_idx,\n",
    "        test_end_idx=test_end_idx,\n",
    "        valid_nodes=valid_nodes,\n",
    "        times=times,\n",
    "        meta=meta,\n",
    "        feature_cols=feature_cols,\n",
    "        target_cols=target_cols,\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================\n",
    "# d) STGNN with windowing (multi-step, multi-target)\n",
    "# =============================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, GatedGraphConv, GATConv\n",
    "\n",
    "\n",
    "class STGNNWindowMultiRegressor(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dim: int,\n",
    "        out_dim: int,\n",
    "        in_dim: int = 1,\n",
    "        gnn_type: str = \"sage\",           # \"sage\", \"ggnn\", \"gat\", ...\n",
    "        temporal_type: str = \"gru\",       # \"gru\", \"lstm\", \"attn\"\n",
    "        attn_heads: int = 4,              # only for \"attn\"\n",
    "        spatial_pool: str = \"mean\",       # \"mean\" oder \"last\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.gnn_type = gnn_type\n",
    "        self.temporal_type = temporal_type\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.spatial_pool = spatial_pool\n",
    "\n",
    "        # ----- Node-Embedding + Input-Projektion -----\n",
    "        self.emb = nn.Embedding(num_nodes, embed_dim)\n",
    "        self.proj = nn.Linear(in_dim + embed_dim, hidden_dim)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # ----- spatial GNN -----\n",
    "        if gnn_type == \"sage\":\n",
    "            self.gnn_layer = SAGEConv(hidden_dim, hidden_dim)\n",
    "        elif gnn_type == \"ggnn\":\n",
    "            self.gnn_layer = GatedGraphConv(out_channels=hidden_dim, num_layers=1)\n",
    "        elif gnn_type == \"gat\":\n",
    "            self.gnn_layer = GATConv(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                heads=1,\n",
    "                concat=False,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown gnn_type: {gnn_type}\")\n",
    "\n",
    "        # ----- temporary module -----\n",
    "        if temporal_type == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=False)\n",
    "        elif temporal_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=False)\n",
    "        elif temporal_type == \"attn\":\n",
    "            self.attn = nn.MultiheadAttention(\n",
    "                embed_dim=hidden_dim,\n",
    "                num_heads=attn_heads,\n",
    "                batch_first=False,  # [W, N, H]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown temporal_type: {temporal_type}\")\n",
    "\n",
    "        # ----- Gating fusion + head -----\n",
    "        # Gate receives [h_spat || h_temp] and outputs a feature gate [N, H]\n",
    "        self.gate_layer = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Auxilary functions\n",
    "    # -------------------------------------------------\n",
    "    def _apply_spatial(self, h: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        h: [N, hidden_dim]\n",
    "        \"\"\"\n",
    "        h = self.gnn_layer(h, edge_index)\n",
    "        h = self.act(h)\n",
    "        return h\n",
    "\n",
    "    def _apply_temporal(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        seq: [W, N, hidden_dim]\n",
    "        Rückgabe: [N, hidden_dim]\n",
    "        \"\"\"\n",
    "        if self.temporal_type == \"gru\":\n",
    "            out, h_n = self.rnn(seq)         # h_n: [num_layers, N, H]\n",
    "            last = h_n[-1]                   # [N, H]\n",
    "            return last\n",
    "\n",
    "        elif self.temporal_type == \"lstm\":\n",
    "            out, (h_n, c_n) = self.rnn(seq)  # h_n: [num_layers, N, H]\n",
    "            last = h_n[-1]                   # [N, H]\n",
    "            return last\n",
    "\n",
    "        elif self.temporal_type == \"attn\":\n",
    "            attn_out, _ = self.attn(seq, seq, seq)  # [W, N, H]\n",
    "            last = attn_out[-1]                     # [N, H]\n",
    "            # last = attn_out.mean(dim=0)\n",
    "            return last\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown temporal_type: {self.temporal_type}\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Parallel-Forward with Gating\n",
    "    # -------------------------------------------------\n",
    "    def forward(self, x_window: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x_window: [W, N, F]\n",
    "        edge_index: [2, E]\n",
    "        \"\"\"\n",
    "        W, N, F = x_window.shape\n",
    "\n",
    "        # shared hidden h_seq: [W, N, H]\n",
    "        node_emb = self.emb.weight                                # [N, embed_dim]\n",
    "        node_emb_exp = node_emb.unsqueeze(0).expand(W, -1, -1)    # [W, N, embed_dim]\n",
    "\n",
    "        h = torch.cat([x_window, node_emb_exp], dim=2)            # [W, N, F + embed_dim]\n",
    "        h = self.proj(h)                                          # [W, N, H]\n",
    "        h = self.act(h)\n",
    "\n",
    "        # ----- temporal branch -----\n",
    "        h_temp = self._apply_temporal(h)                          # [N, H]\n",
    "\n",
    "        # ----- spatial branch -----\n",
    "        gnn_out_per_t = []\n",
    "        for t in range(W):\n",
    "            ht = h[t]                                             # [N, H]\n",
    "            ht_spat = self._apply_spatial(ht, edge_index)         # [N, H]\n",
    "            gnn_out_per_t.append(ht_spat)\n",
    "\n",
    "        h_spat_seq = torch.stack(gnn_out_per_t, dim=0)            # [W, N, H]\n",
    "\n",
    "        if self.spatial_pool == \"mean\":\n",
    "            h_spat = h_spat_seq.mean(dim=0)                       # [N, H]\n",
    "        elif self.spatial_pool == \"last\":\n",
    "            h_spat = h_spat_seq[-1]                               # [N, H]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown spatial_pool: {self.spatial_pool}\")\n",
    "\n",
    "        # ----- Gating-Fusion -----\n",
    "        # concat: [N, 2H]\n",
    "        h_cat = torch.cat([h_spat, h_temp], dim=-1)\n",
    "\n",
    "        # Gate: [N, H] with values in (0, 1)\n",
    "        gate = torch.sigmoid(self.gate_layer(h_cat))\n",
    "\n",
    "        # Feature-wise blending of spatial and temporal\n",
    "        h_fused = gate * h_spat + (1.0 - gate) * h_temp           # [N, H]\n",
    "        h_fused = self.act(h_fused)\n",
    "\n",
    "        out = self.head(h_fused)                                  # [N, out_dim]\n",
    "        return out\n",
    "\n",
    "    \n",
    "# =============================\n",
    "# e) Training and evaluation (multi-step, multi-target)\n",
    "# =============================\n",
    "\n",
    "@dataclass\n",
    "class STTrainConfig:\n",
    "    lr: float = LR\n",
    "    weight_decay: float = WEIGHT_DECAY\n",
    "    epochs: int = EPOCHS\n",
    "    patience: int = PATIENCE\n",
    "    window_size: int = WINDOW_SIZE\n",
    "    horizon_steps: int = HORIZON_STEPS  # per Target\n",
    "\n",
    "\n",
    "def _compute_window_metrics_multi(\n",
    "    model: nn.Module,\n",
    "    data: STWindowDataMulti,\n",
    "    end_indices: np.ndarray,\n",
    "    device: torch.device,\n",
    "    loss_nodes: torch.Tensor,\n",
    "    window_size: int,   \n",
    ") -> dict:\n",
    "\n",
    "    x_full = data.x.to(device)\n",
    "    y_full = data.y.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    W = window_size\n",
    "\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for end_t in end_indices:\n",
    "            start_t = end_t - W + 1\n",
    "            x_win = x_full[start_t:end_t+1]\n",
    "            y_target = y_full[end_t]     # [N, H * M]\n",
    "\n",
    "            pred = model(x_win, edge_index)  # [N, H * M]\n",
    "\n",
    "            y_nodes = y_target[loss_nodes]\n",
    "            p_nodes = pred[loss_nodes]\n",
    "\n",
    "            mask = torch.isfinite(y_nodes)\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            preds_all.append(p_nodes[mask].cpu().numpy())\n",
    "            trues_all.append(y_nodes[mask].cpu().numpy())\n",
    "\n",
    "    if len(preds_all) == 0:\n",
    "        return {\"MAE\": float(\"nan\"), \"RMSE\": float(\"nan\")}\n",
    "\n",
    "    preds_concat = np.concatenate(preds_all)\n",
    "    trues_concat = np.concatenate(trues_all)\n",
    "\n",
    "    mae = np.mean(np.abs(preds_concat - trues_concat))\n",
    "    mse = np.mean((preds_concat - trues_concat) ** 2)\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    "\n",
    "\n",
    "def train_stgnn_window_multi(\n",
    "    data: STWindowDataMulti,\n",
    "    cfg: STTrainConfig,\n",
    "    gnn_type: str = \"sage\",\n",
    "    temporal_type: str = \"gru\",\n",
    "    attn_heads: int = 4,\n",
    ") -> dict:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_full = data.x.to(device)\n",
    "    y_full = data.y.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    W = cfg.window_size\n",
    "\n",
    "    M = len(data.target_cols)\n",
    "    H_per_target = cfg.horizon_steps\n",
    "    out_dim = H_per_target * M   # H * num_targets\n",
    "    in_dim = x_full.shape[2]     # num_features\n",
    "\n",
    "    model = STGNNWindowMultiRegressor(\n",
    "        num_nodes=x_full.shape[1],\n",
    "        embed_dim=EMBED_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        out_dim=out_dim,\n",
    "        in_dim=in_dim,\n",
    "        gnn_type=gnn_type,\n",
    "        temporal_type=temporal_type,\n",
    "        attn_heads=attn_heads,\n",
    "    ).to(device)\n",
    "\n",
    "    opt = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    loss_nodes = torch.tensor(data.valid_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float(\"inf\")\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for end_t in data.train_end_idx:\n",
    "            start_t = end_t - W + 1\n",
    "\n",
    "            x_win = x_full[start_t:end_t+1]\n",
    "            y_target = y_full[end_t]   # [N, H*M]\n",
    "\n",
    "            pred = model(x_win, edge_index)  # [N, H*M]\n",
    "\n",
    "            y_nodes = y_target[loss_nodes]\n",
    "            p_nodes = pred[loss_nodes]\n",
    "\n",
    "            mask = torch.isfinite(y_nodes)\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            loss = loss_fn(p_nodes[mask], y_nodes[mask])\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        avg_train_loss = epoch_loss / max(count, 1)\n",
    "\n",
    "        val_metrics = _compute_window_metrics_multi(model, data, data.val_end_idx, device, loss_nodes, cfg.window_size)\n",
    "        val_mae = val_metrics[\"MAE\"]\n",
    "\n",
    "        #print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_MAE={val_mae:.4f}\")\n",
    "\n",
    "        if val_mae < best_val:\n",
    "            best_val = val_mae\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= cfg.patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    test_metrics = _compute_window_metrics_multi(model, data, data.test_end_idx, device, loss_nodes, cfg.window_size)\n",
    "    val_metrics = _compute_window_metrics_multi(model, data, data.val_end_idx, device, loss_nodes, cfg.window_size)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"metrics\": {\n",
    "            \"val\": val_metrics,\n",
    "            \"test\": test_metrics,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================\n",
    "# f) High-level API\n",
    "# =============================\n",
    "\n",
    "def train_stgnn_window_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    seed: int = SEED,\n",
    "    window_size: int = WINDOW_SIZE,\n",
    "    horizon_steps: int = HORIZON_STEPS,\n",
    "    feature_cols: Optional[List[str]] = None,\n",
    "    target_cols: Optional[List[str]] = None,\n",
    "    stride: int = 1, \n",
    "    gnn_type: str = \"sage\",   \n",
    "    temporal_type: str = \"gru\",\n",
    "    attn_heads: int = 4,\n",
    ") -> dict:\n",
    "\n",
    "    set_seed(seed)\n",
    "    data = make_window_data_multi_from_df(\n",
    "        df,\n",
    "        window_size=window_size,\n",
    "        horizon_steps=horizon_steps,\n",
    "        feature_cols=feature_cols,\n",
    "        target_cols=target_cols,\n",
    "        stride=stride, \n",
    "    )\n",
    "    cfg = STTrainConfig(window_size=window_size, horizon_steps=horizon_steps)\n",
    "    result = train_stgnn_window_multi(\n",
    "        data,\n",
    "        cfg,\n",
    "        gnn_type=gnn_type,\n",
    "        temporal_type=temporal_type,\n",
    "        attn_heads=attn_heads,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"model\": result[\"model\"],\n",
    "        \"metrics\": result[\"metrics\"],\n",
    "        \"data\": data,\n",
    "        \"window_size\": window_size,\n",
    "        \"horizon_steps\": horizon_steps,\n",
    "        \"feature_cols\": data.feature_cols,\n",
    "        \"target_cols\": data.target_cols,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Val: {'MAE': 0.015028496272861958, 'RMSE': 0.019202405499193314}\n",
      "Test: {'MAE': 0.025361239910125732, 'RMSE': 0.033157957785040784}\n"
     ]
    }
   ],
   "source": [
    "# Baseline Experiment\n",
    "Baseline = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size=8,\n",
    "    horizon_steps=2,    \n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Baseline\")\n",
    "print(\"Val:\", Baseline[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Baseline[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Testing different Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1a - E10\n",
    "Experiment1a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e10\"],\n",
    "    target_cols=[\"e10\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 1a - E10\")\n",
    "print(\"Val:\", Experiment1a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment1a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1b - Diesel\n",
    "Experiment1b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"diesel\"],\n",
    "    target_cols=[\"diesel\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 1b - Diesel\")\n",
    "print(\"Val:\", Experiment1b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment1b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1c - Alle petrol types\n",
    "Experiment1c = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\"],\n",
    "    target_cols=[\"e5\", \"e10\", \"diesel\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 1c - All Petrol Types\")\n",
    "print(\"Val:\", Experiment1c[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment1c[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Testing different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2a - Only Prices \n",
    "Experiment2a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "print(\"Experiment 2a - Only Prices\")\n",
    "print(\"Val:\", Experiment2a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment2a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2b - Prices and Days\n",
    "Experiment2b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\", \"weekday\", \"holiday\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 2b - Prices and Days\")\n",
    "print(\"Val:\", Experiment2b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment2b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2c - Prices, Days and Time\n",
    "Experiment2c = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\", \"weekday\", \"holiday\", \"time_sin\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 2c - Prices, Days and Time\")\n",
    "print(\"Val:\", Experiment2c[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment2c[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2d - Prices, Days, Time and Brand\n",
    "Experiment2d = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\", \"weekday\", \"holiday\", \"time_sin\", \"brand_cat\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 2d - Prices, Days, Time and Brand\")\n",
    "print(\"Val:\", Experiment2d[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment2d[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2e - Full features\n",
    "Experiment2e = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\", \"e10\", \"diesel\", \"weekday\", \"holiday\", \"time_sin\", \"brand_cat\", \"Brent_Price\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 2e - Full features\")\n",
    "print(\"Val:\", Experiment2e[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment2e[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Testing different Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3a - Window Size: 16\n",
    "Experiment3a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 16,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 3a - Window Size: 16\")\n",
    "print(\"Val:\", Experiment3a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment3a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3b - Window Size: 32\n",
    "Experiment3b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 32,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 3b - Window Size: 32\")\n",
    "print(\"Val:\", Experiment3b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment3b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3c - Window Size: 48\n",
    "Experiment3c = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 48,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 3c - Window Size: 48\")\n",
    "print(\"Val:\", Experiment3c[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment3c[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3d - Window Size: 96\n",
    "Experiment3d = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 96,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 3d - Window Size: 96\")\n",
    "print(\"Val:\", Experiment3d[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment3d[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Testing different Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4a - Horizon: 4\n",
    "Experiment4a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 4,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 4a - Horizon: 4\")\n",
    "print(\"Val:\", Experiment4a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment4a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4b - Horizon: 8\n",
      "Val: {'MAE': 0.015349118039011955, 'RMSE': 0.019514059906244698}\n",
      "Test: {'MAE': 0.02540482021868229, 'RMSE': 0.0339113739422546}\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4b - Horizon: 8\n",
    "Experiment4b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size=8,\n",
    "    horizon_steps=8,   \n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 4b - Horizon: 8\")\n",
    "print(\"Val:\", Experiment4b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment4b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Testing different Time Intervalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5a - Time Intervall: 30min\n",
    "Experiment5a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 2,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 5a - Time Intervall: 30min\")\n",
    "print(\"Val:\", Experiment5a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment5a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5b - Time Intervall: 60min\n",
    "Experiment5b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 4,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 5b - Time Intervall: 60min\")\n",
    "print(\"Val:\", Experiment5b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment5b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Testing different GNN Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 7a - Recurrent GNN\n",
    "Experiment7a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"ggnn\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 7a - Recurrent GNN\")\n",
    "print(\"Val:\", Experiment7a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment7a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 7b - Attentional GNN\n",
    "Experiment7b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"gat\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"gru\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 7b - Attentional GNN\")\n",
    "print(\"Val:\", Experiment7b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment7b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Testing different Temporal Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 8a - LSTM\n",
    "Experiment8a = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"lstm\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 8a - LSTM\")\n",
    "print(\"Val:\", Experiment8a[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment8a[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 8b - Self-Attention\n",
    "Experiment8b = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"sage\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"attn\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 8b - Self-Attention\")\n",
    "print(\"Val:\", Experiment8b[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment8b[\"metrics\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 8c - Self-Attention and Attentional GNN\n",
    "Experiment8c = train_stgnn_window_from_df(\n",
    "    df,\n",
    "    feature_cols=[\"e5\"],\n",
    "    target_cols=[\"e5\"],\n",
    "    window_size = 8,\n",
    "    horizon_steps = 2,\n",
    "    stride= 1,             # Intveralls: 1--> 15min // 2 --> 30min // 4 --> 60min,\n",
    "    gnn_type= \"gat\",      # Convolutional GNN: sage // Recurrent GNN: ggnn // Attentional GNN: gat,\n",
    "    temporal_type= \"attn\",  # GRU: gru // LSTM: lstm // Self-Attention: attn\n",
    ")\n",
    "\n",
    "print(\"Experiment 8c - Self-Attention\")\n",
    "print(\"Val:\", Experiment8c[\"metrics\"][\"val\"])\n",
    "print(\"Test:\", Experiment8c[\"metrics\"][\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
